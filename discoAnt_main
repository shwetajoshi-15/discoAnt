#!/usr/bin/env bash

# get directory of discoAnt script
SCRIPT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )

# update to v3?
echo "discoAnt v2.1"

# source parameters file
source ${1}

echo \
"
██████  ██ ███████  ██████  ██████   █████  ███    ██ ████████ 
██   ██ ██ ██      ██      ██    ██ ██   ██ ████   ██    ██    
██   ██ ██ ███████ ██      ██    ██ ███████ ██ ██  ██    ██    
██   ██ ██      ██ ██      ██    ██ ██   ██ ██  ██ ██    ██    
██████  ██ ███████  ██████  ██████  ██   ██ ██   ████    ██ 
"

# add section here to check if the $GENE directory already exists, if it does, exit
if [ -d $GENE ] 
then
	echo "$GENE already exists."
	exit 1  # Exit the script with a non-zero status code (1)
fi

# make directories
mkdir -p $GENE
mkdir -p $GENE/samples
mkdir -p $GENE/minimap2
mkdir -p $GENE/bambu
mkdir -p $GENE/metagene_salmon
mkdir -p $GENE/filtered_transcripts
mkdir -p $GENE/discarded_transcripts
mkdir -p $GENE/gffcomp_outs
mkdir -p $GENE/temp_files

# filter reference files and index reference genome
echo "Indexing and filtering reference files"

# GTF
grep $ENSG_ID $ANNA_GTF > $GENE/temp_files/filt_chr.gtf
ANNA_GTF_filt=$GENE/temp_files/filt_chr.gtf

# FASTA
samtools faidx $REF_GENOME_FN $chr -o $GENE/temp_files/filt_chr.fa
REF_GENOME_FN_filt=$GENE/temp_files/filt_chr.fa


# new function to check that fastq(.gz) and fasta files are in the FASTA DIR and that FASTA dir exists
function check_for_fastq_or_fasta_files() {

	if [ -d "$FASTA" ] 
	then
        echo "Finding reads in $FASTA"
        
        # Use find to search for FASTQ or FASTA files
        if find "$FASTA" -type f \( -name "*.fastq"  -o -name "*.fastq.gz" -o -name "*.fasta" -o -name "*.fa" \) -print -quit | grep -q . 
		then
            echo "FASTQ or FASTA files found."
            # Call the next function or perform the next task here
        else
            echo "No FASTQ or FASTA files found within subdirectories of $FASTA. Exiting."
            exit 1  # Exit the script with a non-zero status code (1)
        fi

    else
        echo "Directory not found: $FASTA. Exiting."
        exit 1  # Exit the script with a non-zero status code (1)
    fi
    
}

# new function to check that fastq(.gz) and fasta files are in the FASTA DIR and that FASTA dir exists
function concat_files() {
	
	mkdir $GENE/samples/reads

	# run on all subdirectories in $FASTA
	find "$FASTA" -type d -mindepth 1 -maxdepth 1 | while read -r dir
	do

		# Use basename to extract just the directory name
		dir_name=$(basename "$dir")

		# if BBMap works on gzipped files this may not be required, minimap2 works on gzipped files
		# Gunzip zipped files
		for gzipped_file in "$FASTA/$dir_name"/*.gz 
		do
			if [ -f "$gzipped_file" ] 
			then
				echo "Unzipping $gzipped_file"
				gunzip "$gzipped_file"
			fi
		done
		
		# combine all sample read files into one file
		cat $FASTA/$dir_name/*.fa* > $GENE/samples/reads/$dir_name.fa

	done
    
}

# new downsample_function
function downsampling_function() {
	if [ "$downsampling" == TRUE ]
	then

		echo "Downsampling reads"
		mkdir -p $GENE/samples/downsample_$number_reads_downsample

		for filename in $GENE/samples/reads/*.fa
		do

        	base=$(basename "$filename")
        	sample_name="${base%.*}" 
			echo "$sample_name downsampling"
			## Downsample the reads
			## reformat.sh is from BBMap
			reformat.sh sample=$number_reads_downsample \
			in=$GENE/samples/reads/$sample_name.fa \
			out=$GENE/samples/downsample_$number_reads_downsample/$sample_name.fa

		done

	fi

	# report metrics
	#num_of_barcodes=$( ls -lh $FASTA/*.f* | wc -l )
	#total_reads_pass=$(awk '{ sum += $1 } END { print sum }' $GENE/no_of_reads_pass_barcodewise_tmp.txt)
	#total_reads_pass_post_dwnsmp=$(awk '{ sum += $1 } END { print sum }' $GENE/no_of_reads_barcodewise_postdwnsmp_tmp.txt)
	#total_reads=$(awk '{ sum += $1 } END { print sum }' $GENE/temp_files/no_of_reads_barcodewise_tmp.txt)
	#read_supp_for_transcript=$(echo $total_reads \* $readFraction_for_bambu  | bc)

}


function mapping_genome_function() {
  # define max intron length for minimap2
  if [ -z "$max_intron_length" ] 
  then
    max_intron_length="400" # Set to the default value if max_intron_length is empty
  fi
  
  if [ "$downsampling" == TRUE ]
  then

  	path_to_reads=$GENE/samples/downsample_$number_reads_downsample

  elif [ "$downsampling" == FALSE ]
  then

	path_to_reads=$GENE/samples/reads

  fi

  echo "Aligning reads with minimap2"
  for filename in "$path_to_reads"/*.fa
  do

    base=$(basename "$filename")
    sample_reads="${base%.*}" 
    
    minimap2 -ax splice -G"${max_intron_length}"k --splice-flank=yes --eqx $REF_GENOME_FN_filt $GENE/samples/reads/${sample_reads}.fa > $GENE/minimap2/${sample_reads}.sam
    samtools view -S -h -b $GENE/minimap2/${sample_reads}.sam | samtools sort - > $GENE/minimap2/${sample_reads}_sorted.bam
  	samtools view -h -F 2308 $GENE/minimap2/${sample_reads}_sorted.bam | samtools sort - > $GENE/minimap2/${sample_reads}_pri_sorted.bam
	
  done

  samtools merge -f $GENE/minimap2/$GENE_pri_merged.bam $GENE/minimap2/*_pri_sorted.bam

  samtools merge -f $GENE/minimap2/$GENE_merged.bam $GENE/minimap2/*_sorted.bam

  samtools index $GENE/minimap2/$GENE_pri_merged.bam
  samtools index $GENE/minimap2/$GENE_merged.bam
  
}

function run_bambu_function() {
	echo "Finding novel isoforms with Bambu"

	# if bambu is the latest version, NDR has to be in opts list, if not, NDR is its own arg
	Rscript $SCRIPT_DIR/scripts/bambu_tx_discovery.R -b $GENE/minimap2/$GENE_pri_merged.bam \
		-f $REF_GENOME_FN_filt \
		-t $ANNA_GTF_filt \
		-r $readFraction_for_bambu \
		-o $GENE/bambu

	# what are these counts for? Don't think we need.
	#awk 'FNR==NR{s+=$2;next;} {printf "%s\t%s\t%s%%\n",$1,$2,100*$2/s}' $GENE/bambu/uniqueCounts.txt $GENE/bambu/uniqueCounts.txt > $GENE/bambu/uniqueCounts_perc.txt
	#awk 'FNR==NR{s+=$2;next;} {printf "%s\t%s\t%s%%\n",$1,$2,100*$2/s}' $GENE/bambu/CPM.txt $GENE/bambu/CPM.txt > $GENE/bambu/CPM_perc.txt
}

function primer_site_function() {
	if [ "$primer_site_based_filter" == TRUE ]
	then
		
		echo "Primer site filtering on"
		# used to be a 5bp window created around primers, do we need this?
		# write out isoforms which don't match any primers
		bedtools subtract -A -a $GENE/bambu/extended_annotations.gtf -b $forward_primers | bedtools subtract -A -a - -b $reverse_primers > $GENE/filtered_transcripts/extended_annotations_no_primer_overlap.gtf
			
		# write out isoforms which do match primers
		bedtools intersect -wa -u -a $GENE/bambu/extended_annotations.gtf -b $forward_primers | bedtools intersect -wa -a - -b $reverse_primers > $GENE/filtered_transcripts/extended_annotations_with_primer_overlap.gtf

		cat $GENE/filtered_transcripts/extended_annotations_with_primer_overlap.gtf | awk '{ if ($3 == "transcript") print $12 }' | sed 's/"//g' | sed 's/;//g' > $GENE/filtered_transcripts/transcripts_primer_overlap.txt

	fi
}

function read_count_function_first_pass() {

	if [ "$primer_site_based_filter" == TRUE ]
	then
		cat $GENE/bambu/bambu_read_counts.txt | grep -wf $GENE/filtered_transcripts/transcripts_primer_overlap.txt | awk '{ if ($2 > 1) print }' > $GENE/filtered_transcripts/transcripts_read_counts_more_than_1.txt
	elif [ "$primer_site_based_filter" == FALSE ]
	then
		cat $GENE/bambu/bambu_read_counts.txt |  awk '{ if ($2 > 1) print }' > $GENE/filtered_transcripts/transcripts_read_counts_more_than_1.txt
	fi

	cat $GENE/filtered_transcripts/transcripts_read_counts_more_than_1.txt | awk '{ print $1 }' > $GENE/filtered_transcripts/transcripts_read_counts_more_than_1_list_tmp.txt

	cat $GENE/bambu/extended_annotations.gtf | grep -wf $GENE/filtered_transcripts/transcripts_read_counts_more_than_1_list_tmp.txt > $GENE/bambu/extended_annotations_read_count_more_than_1.gtf
	cat $GENE/bambu/extended_annotations.gtf | grep -v -wf $GENE/filtered_transcripts/transcripts_read_counts_more_than_1_list_tmp.txt > $GENE/discarded_transcripts/extended_annotations_read_count_more_than_1_discarded.gtf
			
	# Removing temporary files 
	rm $GENE/filtered_transcripts/transcripts_read_counts_more_than_1_list_tmp.txt

	sed 's/tx./tx/g' $GENE/bambu/extended_annotations_read_count_more_than_1.gtf > $GENE/${ENSG_ID}_discoAnt_isoforms_pass1.gtf
	cat $GENE/filtered_transcripts/transcripts_read_counts_more_than_1.txt | sed 's/tx./tx/g' | awk '{ print $1"\t"$3}' > $GENE/filtered_transcripts/filtered_transcripts.txt

}

function create_metatranscriptome() {
	echo "Creating a metatranscriptome based on the filtered transcripts"

	gffread -w $GENE/filtered_transcripts/filtered_transcripts.fa -g $REF_GENOME_FN_filt $GENE/${ENSG_ID}_discoAnt_isoforms_pass1.gtf
	salmon index -t $GENE/filtered_transcripts/filtered_transcripts.fa -i $GENE/filtered_transcripts -k 31

}

function remapping_function() {

	echo "Quantifying with salmon"

	for filename in $path_to_reads/*.fa
	do

		base=$(basename $filename .fa)
		echo "On sample $base"

		salmon quant --quiet -i $GENE/filtered_transcripts -l A -r $path_to_reads/${base}.fa -o $GENE/metagene_salmon/${base}

	done

}

function combine_quants_function() {
	echo "Generating isoform counts"
	Rscript $SCRIPT_DIR/scripts/combine_salmon_quants.R -e $ENSG_ID -m $read_count_minimum -o $GENE
}

function read_count_function_second_pass() {
	echo "Filtering isoforms with read count minimum of: $read_count_minimum" 
	# create list in text file of isoforms that passed threshold
	# command uses _ and , as sep, prints first column of tx names, removes the word Bambu in tx names, and removes the column header
	cat $GENE/${ENSG_ID}_discoAnt_counts.csv | awk -F '[_,]' '{print $1}' | sed 's/Bambu//g' | tail -n +2 > $GENE/filtered_transcripts/transcripts_read_counts_second_pass_list_tmp.txt
	# filter GTF based on isoforms 
	cat $GENE/${ENSG_ID}_discoAnt_isoforms_pass1.gtf | grep -wif $GENE/filtered_transcripts/transcripts_read_counts_second_pass_list_tmp.txt > $GENE/${ENSG_ID}_discoAnt_isoforms.gtf

	# Removing temporary files 
	#rm $GENE/filtered_transcripts/transcripts_read_counts_more_than_1_second_pass_list_tmp.txt
	
	#echo "Editing filtered GTF files for use with IsoMix"
	#sed 's/tx./tx/g' $GENE/bambu/extended_annotations_read_count_more_than_1.gtf > $GENE/${ENSG_ID}_discoAnt_isoforms.gtf
	#cat $GENE/filtered_transcripts/transcripts_read_counts_more_than_1.txt | sed 's/tx./tx/g' | awk '{ print $1"\t"$3}' > $GENE/filtered_transcripts/filtered_transcripts.txt
	filtered_transcripts_known=$( cat $GENE/filtered_transcripts/transcripts_read_counts_second_pass_list_tmp.txt | grep -vi tx | wc -l )
	filtered_transcripts_novel=$( cat $GENE/filtered_transcripts/transcripts_read_counts_second_pass_list_tmp.txt | grep -i tx | wc -l )

}

function gffcomp_function() {
	echo "Annotating isoforms with gffcompare"
	gffcompare -r $ANNA_GTF_filt -o $GENE/gffcomp_outs/gffcomp $GENE/${ENSG_ID}_discoAnt_isoforms.gtf
	mv $GENE/gffcomp.* $GENE/gffcomp_outs/
}

function sqanti_function() {
	if [ "$run_sqanti" == TRUE ]
  	then

		echo "Annotating isoforms with SQANTI"

 		# source python paths for cDNA Cupcake to run with SQANTI
  		export PYTHONPATH="$SCRIPT_DIR/scripts/cDNA_Cupcake/sequence/:$PYTHONPATH"
  		export PYTHONPATH="$SCRIPT_DIR/scripts/cDNA_Cupcake/:$PYTHONPATH"
  
		
		python $SCRIPT_DIR/scripts/SQANTI3/sqanti3_qc.py \
			$GENE/${ENSG_ID}_discoAnt_isoforms.gtf \
			$ANNA_GTF_filt $REF_GENOME_FN_filt \
			-d $GENE/sqanti -o $GENE --report skip
			#--CAGE_peak $REF_HG38/refTSS_v3.3_human_coordinate.hg38.bed \
			#--polyA_peak $REF_HG38/atlas.clusters.2.0.GRCh38.96.bed --polyA_motif_list $REF_HG38/human.polyA.list.txt
	fi
}

function generate_report_function() {
	cat << EOT >> $GENE/${ENSG_ID}_discoAnt_report.txt
	`date`

	These three won't work currently:
	Number of input samples/barcodes: $num_of_barcodes
	Number of reads across barcodes: $total_reads_pass
	Number of reads across barcodes post-downsampling: 

	Filters applied:
		Primer site filter: $primer_site_based_filter
		Downsampling: $downsampling
		Downsampled to number of reads: $number_reads_downsample
		Read count minimum: $read_count_minimum

	Known isoforms identified: $filtered_transcripts_known
	Novel isoforms identified: $filtered_transcripts_novel

EOT
}


########## 0. Counting the number of reads and downsampling ##########

# check filetypes
check_for_fastq_or_fasta_files
concat_files

# Downsampling
downsampling_function


########## 1. Aligning sample fasta files to reference genome ##########

#### run mapping and suppress output
mapping_genome_function


########## 2.a. Correcting and collapsing transcripts with bambu ##########

# suppressing output here breaks it for some reason...
##### if suppressed it breaks the primer_site_function part
run_bambu_function


########## 2.b. Filtering bambu transcripts and creating a transcriptome ##########

# Primer site filter
primer_site_function

# Read count filter 
read_count_function_first_pass

# metatranscriptome with salmon
create_metatranscriptome


########## 2.c. Re-aligning and quantifying filtered bambu transcripts  ##########

# remap to salmon metatranscriptome
remapping_function


########## 2.d. Generating count matrix   ##########

# Rscript to combine quant.sf files and filter by read min counts
combine_quants_function

# some zero count isoforms result after the secound round of quants with salmon
read_count_function_second_pass


########## 3. Annotating transcripts ##########

# run with gffcompare
gffcomp_function

# run with SQANTI
sqanti_function


########## 4. Report ##########

# make report txt file
generate_report_function


########## Finished ##########

# removing temp files
# currently commented out while de-bugging
# more of the extra files should be put into tmp and deleted
#rm -rf $GENE/temp_files
#rm $GENE/${ENSG_ID}_discoAnt_isoforms_pass1.gtf
#rm $GENE/minimap2/*.sam

echo "
██████  ██ ███████  ██████  ██████   █████  ███    ██ ████████      ██████  ██████  ███    ███ ██████  ██      ███████ ████████ ███████ 
██   ██ ██ ██      ██      ██    ██ ██   ██ ████   ██    ██        ██      ██    ██ ████  ████ ██   ██ ██      ██         ██    ██      
██   ██ ██ ███████ ██      ██    ██ ███████ ██ ██  ██    ██        ██      ██    ██ ██ ████ ██ ██████  ██      █████      ██    █████   
██   ██ ██      ██ ██      ██    ██ ██   ██ ██  ██ ██    ██        ██      ██    ██ ██  ██  ██ ██      ██      ██         ██    ██      
██████  ██ ███████  ██████  ██████  ██   ██ ██   ████    ██         ██████  ██████  ██      ██ ██      ███████ ███████    ██    ███████ "                                                                                                                                        
