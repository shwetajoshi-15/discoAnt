#!/usr/bin/env bash

# get directory of discoAnt script
SCRIPT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )

# update to v3?
echo "discoAnt v2.1"

# source parameters file
source ${1}

echo \
"
██████  ██ ███████  ██████  ██████   █████  ███    ██ ████████ 
██   ██ ██ ██      ██      ██    ██ ██   ██ ████   ██    ██    
██   ██ ██ ███████ ██      ██    ██ ███████ ██ ██  ██    ██    
██   ██ ██      ██ ██      ██    ██ ██   ██ ██  ██ ██    ██    
██████  ██ ███████  ██████  ██████  ██   ██ ██   ████    ██ 
"

# add section here to check if the $GENE directory already exists, if it does, exit
if [ -d $GENE ] 
then
	echo "$GENE already exists"
	exit 1  # Exit the script with a non-zero status code (1)
fi

# make directories
mkdir -p $GENE
mkdir -p $GENE/samples
mkdir -p $GENE/minimap2
mkdir -p $GENE/bambu
mkdir -p $GENE/metagene_salmon
mkdir -p $GENE/filtered_transcripts
mkdir -p $GENE/discarded_transcripts
mkdir -p $GENE/gffcomp_outs
mkdir -p $GENE/temp_files

# filter reference files and index reference genome
echo "Running on reads in: $FASTA"
echo "Indexing and filtering reference files..."

# GTF
grep $ENSG_ID $ANNA_GTF > $GENE/temp_files/filt_chr.gtf
ANNA_GTF_filt=$GENE/temp_files/filt_chr.gtf

# FASTA
samtools faidx $REF_GENOME_FN $chr -o $GENE/temp_files/filt_chr.fa
REF_GENOME_FN_filt=$GENE/temp_files/filt_chr.fa

# Define logs file
log_file="$GENE/discoAnt.logs"
# Function to redirect output to the log file
redirect_output() {
    # Redirect both stdout (1) and stderr (2) to the log file
    {
        "$@"
    } >> "$log_file" 2>&1
}

function check_for_fastq_or_fasta_files() {

	if [ -d "$FASTA" ] 
	then
        
        # Use find to search for FASTQ or FASTA files
        if find "$FASTA" -type f \( -name "*.fastq"  -o -name "*.fastq.gz" -o -name "*.fasta" -o -name "*.fa" \) -print -quit | grep -q . 
		then
            :
			# Call the next function or perform the next task here
        else
            echo "No FASTQ or FASTA files found within subdirectories of $FASTA"
            exit 1  # Exit the script with a non-zero status code
        fi

    else
        echo "Directory not found: $FASTA"
        exit 1  # Exit the script with a non-zero status code
    fi
    
}

function concat_files() {
	
	mkdir $GENE/samples/reads

	# run on all subdirectories in $FASTA
	find "$FASTA" -mindepth 1 -maxdepth 1 -type d | while read -r dir
	do

		# Use basename to extract just the directory name
		dir_name=$(basename "$dir")

		# if BBMap works on gzipped files this may not be required, minimap2 works on gzipped files
		# Gunzip zipped files
		for gzipped_file in "$FASTA/$dir_name"/*.gz 
		do
			if [ -f "$gzipped_file" ] 
			then
				echo "Unzipping $gzipped_file..."
				gunzip "$gzipped_file"
			fi
		done
		
		# combine all sample read files into one file
		cat $FASTA/$dir_name/*.fa* > $GENE/samples/reads/$dir_name.fa

	done
    
}

# new downsample_function
function downsampling_function() {

	if [ "$downsampling" == TRUE ]
	then
		
		if [ -z "$number_reads_downsample" ]
		then
    		number_reads_downsample="8000" # Set to the default value if empty
  		fi

		echo "Downsampling reads..."

		mkdir -p $GENE/samples/downsample_$number_reads_downsample

		downsample_for_loop() { 
			for filename in $GENE/samples/reads/*.fa
			do

				base=$(basename "$filename")
				sample_name="${base%.*}" 
				echo "$sample_name downsampling"
				## Downsample the reads
				## reformat.sh is from BBMap
				reformat.sh sample=$number_reads_downsample \
				in=$GENE/samples/reads/$sample_name.fa \
				out=$GENE/samples/downsample_$number_reads_downsample/$sample_name.fa

			done
		}
		
		redirect_output downsample_for_loop

		path_to_reads=$GENE/samples/downsample_$number_reads_downsample
	
	elif [ "$downsampling" == FALSE ]
	then

		path_to_reads=$GENE/samples/reads

	fi

	# report metrics
	#num_of_barcodes=$( ls -lh $FASTA/*.f* | wc -l )
	#total_reads_pass=$(awk '{ sum += $1 } END { print sum }' $GENE/no_of_reads_pass_barcodewise_tmp.txt)
	#total_reads_pass_post_dwnsmp=$(awk '{ sum += $1 } END { print sum }' $GENE/no_of_reads_barcodewise_postdwnsmp_tmp.txt)
	#total_reads=$(awk '{ sum += $1 } END { print sum }' $GENE/temp_files/no_of_reads_barcodewise_tmp.txt)
	#read_supp_for_transcript=$(echo $total_reads \* $readFraction_for_bambu  | bc)

}


function mapping_genome_function() {
  # define max intron length for minimap2
  if [ -z "$max_intron_length" ] 
  then
    max_intron_length="400" # Set to the default value if max_intron_length is empty
  fi
  
  echo "Mapping reads..."
  for filename in "$path_to_reads"/*.fa
  do

    base=$(basename "$filename")
    sample_reads="${base%.*}" 
    
	map_reads_minimap2() {
    	minimap2 -ax splice -G"${max_intron_length}"k --splice-flank=yes --eqx $REF_GENOME_FN_filt $GENE/samples/reads/${sample_reads}.fa > $GENE/minimap2/${sample_reads}.sam

	}
	redirect_output map_reads_minimap2
	
	samtools view -S -h -b $GENE/minimap2/${sample_reads}.sam | samtools sort - > $GENE/minimap2/${sample_reads}_sorted.bam
  	samtools view -h -F 2308 $GENE/minimap2/${sample_reads}_sorted.bam | samtools sort - > $GENE/minimap2/${sample_reads}_pri_sorted.bam

  done


  samtools merge -f $GENE/minimap2/$GENE_pri_merged.bam $GENE/minimap2/*_pri_sorted.bam

  #samtools merge -f $GENE/minimap2/$GENE_merged.bam $GENE/minimap2/*_sorted.bam

  samtools index $GENE/minimap2/$GENE_pri_merged.bam
  #samtools index $GENE/minimap2/$GENE_merged.bam
   
  if [ -e "$GENE/minimap2/$GENE_pri_merged.bam.bai" ]
  then 
	:
  else
	echo "Failed to create BAM index, check logs file"
	exit 1
  fi
  
}

function run_bambu_function() {
	echo "Identifying novel isoforms with Bambu..."

	# if bambu is the latest version, NDR has to be in opts list, if not, NDR is its own arg
	redirect_output Rscript $SCRIPT_DIR/scripts/bambu_tx_discovery.R -b $GENE/minimap2/$GENE_pri_merged.bam \
		-f $REF_GENOME_FN_filt \
		-t $ANNA_GTF_filt \
		-o $GENE/bambu

	if [ -e "$GENE/bambu/extended_annotations.gtf" ]
  	then 
		:
 	else
		echo "Failed to create Bambu annotations, check logs file"
		exit 1
  	fi

	# what are these counts for? Don't think we need.
	#awk 'FNR==NR{s+=$2;next;} {printf "%s\t%s\t%s%%\n",$1,$2,100*$2/s}' $GENE/bambu/uniqueCounts.txt $GENE/bambu/uniqueCounts.txt > $GENE/bambu/uniqueCounts_perc.txt
	#awk 'FNR==NR{s+=$2;next;} {printf "%s\t%s\t%s%%\n",$1,$2,100*$2/s}' $GENE/bambu/CPM.txt $GENE/bambu/CPM.txt > $GENE/bambu/CPM_perc.txt
}

function primer_site_function() {
	if [ "$primer_site_based_filter" == TRUE ]
	then
		
		echo "Filtering based on primer BED files..."
		# used to be a 5bp window created around primers, do we need this?
		# write out isoforms which don't match any primers
		#bedtools subtract -A -a $GENE/bambu/extended_annotations.gtf -b $forward_primers | bedtools subtract -A -a - -b $reverse_primers > $GENE/filtered_transcripts/extended_annotations_no_primer_overlap.gtf
		
		# write out isoforms which do match primers
		bedtools intersect -wa -u -a $GENE/bambu/extended_annotations.gtf -b $forward_primers | bedtools intersect -wa -a - -b $reverse_primers > $GENE/filtered_transcripts/extended_annotations_with_primer_overlap.gtf

		cat $GENE/filtered_transcripts/extended_annotations_with_primer_overlap.gtf | awk '{ if ($3 == "transcript") print $12 }' | sed 's/"//g' | sed 's/;//g' > $GENE/filtered_transcripts/transcripts_primer_overlap.txt
		
		# Count the number of isoforms kept after primer filtering \
		count_file1=$(awk '$3 == "transcript" {count++} END {print count}' "$GENE/filtered_transcripts/extended_annotations_with_primer_overlap.gtf")
		count_file2=$(awk '$3 == "transcript" {count++} END {print count}' "$GENE/bambu/extended_annotations.gtf")

		# Calculate 20% of the lines in file2
		primer_threshold=$(printf "%.0f" "$(echo "$count_file2 * 0.2" | bc)")

		# Check if count_file1 is greater than half_count_file2
		if [ "$count_file1" -lt "$primer_threshold" ] 
		then
			echo "Warning: more than 80% of the isoforms identified with Bambu were removed after primer site filtering"
		fi

	fi
}

function read_count_function_first_pass() {

	if [ "$primer_site_based_filter" == TRUE ]
	then
		cat $GENE/bambu/bambu_read_counts.txt | grep -wf $GENE/filtered_transcripts/transcripts_primer_overlap.txt | awk '{ if ($2 > 1) print }' > $GENE/filtered_transcripts/transcripts_read_counts_more_than_1.txt
	elif [ "$primer_site_based_filter" == FALSE ]
	then
		cat $GENE/bambu/bambu_read_counts.txt |  awk '{ if ($2 > 1) print }' > $GENE/filtered_transcripts/transcripts_read_counts_more_than_1.txt
	fi

	cat $GENE/filtered_transcripts/transcripts_read_counts_more_than_1.txt | awk '{ print $1 }' > $GENE/filtered_transcripts/transcripts_read_counts_more_than_1_list_tmp.txt

	cat $GENE/bambu/extended_annotations.gtf | grep -wf $GENE/filtered_transcripts/transcripts_read_counts_more_than_1_list_tmp.txt > $GENE/bambu/extended_annotations_read_count_more_than_1.gtf
	cat $GENE/bambu/extended_annotations.gtf | grep -v -wf $GENE/filtered_transcripts/transcripts_read_counts_more_than_1_list_tmp.txt > $GENE/discarded_transcripts/extended_annotations_read_count_more_than_1_discarded.gtf

	sed 's/tx./tx/g' $GENE/bambu/extended_annotations_read_count_more_than_1.gtf > $GENE/${ENSG_ID}_discoAnt_isoforms_pass1.gtf
	cat $GENE/filtered_transcripts/transcripts_read_counts_more_than_1.txt | sed 's/tx./tx/g' | awk '{ print $1"\t"$3}' > $GENE/filtered_transcripts/filtered_transcripts.txt

}

function create_metatranscriptome() {
	echo "Creating an updated transcriptome with novel isoforms..."

	redirect_output gffread -w $GENE/filtered_transcripts/filtered_transcripts.fa -g $REF_GENOME_FN_filt $GENE/${ENSG_ID}_discoAnt_isoforms_pass1.gtf
	redirect_output salmon index -t $GENE/filtered_transcripts/filtered_transcripts.fa -i $GENE/filtered_transcripts -k 31

}

function remapping_function() {

	running_salmon() {
		for filename in $path_to_reads/*.fa
		do

			base=$(basename $filename .fa)
			
			salmon quant --quiet -i $GENE/filtered_transcripts -l A -r $path_to_reads/${base}.fa -o $GENE/metagene_salmon/${base}

		done
	}

	redirect_output running_salmon
}

function combine_quants_function() {
	if [ -z "$read_count_minimum" ]
	then
    	read_count_minimum="5" # Set to the default value if empty
  	fi
	
	echo "Generating isoform counts..."
	Rscript $SCRIPT_DIR/scripts/combine_salmon_quants.R -e $ENSG_ID -m $read_count_minimum -o $GENE
}

function read_count_function_second_pass() {

	# create list in text file of isoforms that passed threshold
	# command uses _ and , as sep, prints first column of tx names, removes the word Bambu in tx names, and removes the column header
	cat $GENE/${ENSG_ID}_discoAnt_counts.csv | awk -F '[_,]' '{print $1}' | sed 's/Bambu//g' | tail -n +2 > $GENE/filtered_transcripts/transcripts_read_counts_second_pass_list_tmp.txt
	# filter GTF based on isoforms 
	cat $GENE/${ENSG_ID}_discoAnt_isoforms_pass1.gtf | grep -wif $GENE/filtered_transcripts/transcripts_read_counts_second_pass_list_tmp.txt > $GENE/${ENSG_ID}_discoAnt_isoforms.gtf

	# Removing temporary files 
	#rm $GENE/filtered_transcripts/transcripts_read_counts_more_than_1_second_pass_list_tmp.txt
	
	#echo "Editing filtered GTF files for use with IsoMix"
	#sed 's/tx./tx/g' $GENE/bambu/extended_annotations_read_count_more_than_1.gtf > $GENE/${ENSG_ID}_discoAnt_isoforms.gtf
	#cat $GENE/filtered_transcripts/transcripts_read_counts_more_than_1.txt | sed 's/tx./tx/g' | awk '{ print $1"\t"$3}' > $GENE/filtered_transcripts/filtered_transcripts.txt
	filtered_transcripts_known=$( cat $GENE/filtered_transcripts/transcripts_read_counts_second_pass_list_tmp.txt | grep -vi tx | wc -l )
	filtered_transcripts_novel=$( cat $GENE/filtered_transcripts/transcripts_read_counts_second_pass_list_tmp.txt | grep -i tx | wc -l )

}

function gffcomp_function() {
	redirect_output gffcompare -r $ANNA_GTF_filt -o $GENE/gffcomp_outs/gffcomp $GENE/${ENSG_ID}_discoAnt_isoforms.gtf
	mv $GENE/gffcomp.* $GENE/gffcomp_outs/
}

function sqanti_function() {
 	# source python paths for cDNA Cupcake to run with SQANTI
  	export PYTHONPATH="$SCRIPT_DIR/scripts/cDNA_Cupcake/sequence/:$PYTHONPATH"
  	export PYTHONPATH="$SCRIPT_DIR/scripts/cDNA_Cupcake/:$PYTHONPATH"
  
		
	python $SCRIPT_DIR/scripts/SQANTI3/sqanti3_qc.py \
		$GENE/${ENSG_ID}_discoAnt_isoforms.gtf \
		$ANNA_GTF_filt $REF_GENOME_FN_filt \
		-d $GENE/sqanti -o $GENE --report skip
		#--CAGE_peak $REF_HG38/refTSS_v3.3_human_coordinate.hg38.bed \
		#--polyA_peak $REF_HG38/atlas.clusters.2.0.GRCh38.96.bed --polyA_motif_list $REF_HG38/human.polyA.list.txt

}

function generate_report_function() {
	cat << EOT >> $GENE/${ENSG_ID}_discoAnt_report.txt
	`date`

	These three won't work currently:
	Number of input samples/barcodes: $num_of_barcodes
	Number of reads across barcodes: $total_reads_pass
	Number of reads across barcodes post-downsampling: 

	Filters applied:
		Primer site filter: $primer_site_based_filter
		Downsampling: $downsampling
		Downsampled to number of reads: $number_reads_downsample
		Read count minimum: $read_count_minimum

	Known isoforms identified: $filtered_transcripts_known
	Novel isoforms identified: $filtered_transcripts_novel

EOT
}


########## 0. Counting the number of reads and downsampling ##########

# check filetypes
check_for_fastq_or_fasta_files
concat_files

# Downsampling
downsampling_function


########## 1. Aligning sample fasta files to reference genome ##########

#### run mapping and suppress output
mapping_genome_function


########## 2.a. Correcting and collapsing transcripts with bambu ##########

# suppressing output here breaks it for some reason...
##### if suppressed it breaks the primer_site_function part
run_bambu_function


########## 2.b. Filtering bambu transcripts and creating a transcriptome ##########

# Primer site filter
primer_site_function

# Read count filter 
read_count_function_first_pass

# metatranscriptome with salmon
create_metatranscriptome


########## 2.c. Re-aligning and quantifying filtered bambu transcripts  ##########

# remap to salmon metatranscriptome
remapping_function


########## 2.d. Generating count matrix   ##########

# Rscript to combine quant.sf files and filter by read min counts
combine_quants_function

# some zero count isoforms result after the secound round of quants with salmon
read_count_function_second_pass


########## 3. Annotating transcripts ##########
echo "Annotating isoforms..."
# run with gffcompare
gffcomp_function

# run with SQANTI
#sqanti_function


########## 4. Report ##########

# make report txt file
echo "Generating report..."
generate_report_function


########## Finished ##########

# removing temp files
# currently commented out while de-bugging
# more of the extra files should be put into tmp and deleted
#rm -rf $GENE/temp_files
#rm $GENE/${ENSG_ID}_discoAnt_isoforms_pass1.gtf
#rm $GENE/minimap2/*.sam
#rm $GENE/filtered_transcripts/transcripts_read_counts_more_than_1_list_tmp.txt

echo "
██████  ██ ███████  ██████  ██████   █████  ███    ██ ████████      ██████  ██████  ███    ███ ██████  ██      ███████ ████████ ███████ 
██   ██ ██ ██      ██      ██    ██ ██   ██ ████   ██    ██        ██      ██    ██ ████  ████ ██   ██ ██      ██         ██    ██      
██   ██ ██ ███████ ██      ██    ██ ███████ ██ ██  ██    ██        ██      ██    ██ ██ ████ ██ ██████  ██      █████      ██    █████   
██   ██ ██      ██ ██      ██    ██ ██   ██ ██  ██ ██    ██        ██      ██    ██ ██  ██  ██ ██      ██      ██         ██    ██      
██████  ██ ███████  ██████  ██████  ██   ██ ██   ████    ██         ██████  ██████  ██      ██ ██      ███████ ███████    ██    ███████ "                                                                                                                                        
